---
title: 'Road to RKHS'
date: 2020-05-22
permalink: /posts/2020/05/blog-post-4/
tags:
  - RKHS
  - functional analysis
  - machine learning
---

Reproducing Kernel Hilbert Space(RKHS) is related to kernel trick in machine learning and plays a significant role in representation learning. In this post, I will summarize the mathematical definition of RKHS.

First, we define the notion of a metric space. a metric space is defined as following:

Let $S$ be a set, and suppose $d$ is a function defined for all pairs $(x, y)$ of elements from $S$ satisfying:
1. Nonnegativity: $d(x, x) = 0 \forall x \in S$ and $d(x, y) > 0$ for distinct $x, y \in S$
2. Symmetry: $d(x, y) = d(y, x) \forall x, y \in S$
3. Triangle Inequality: $d(x, z) \leq d(x, y) + d(y, z) \forall x, y, z \in S$

Such a function $d$ is called a distance function or a metric on $S$. A metric space $S$ is a set $S$ together with a distance metric $d$ on it. A metric space is often written as a pair $(S, d)$. To summarize, a metric space is a set and the distance between it's elements can be measured by the distance metric $d$. This means $S$ has a topological structure, which enables us to study notions of continuity and convergence.

Now we introduce the notion of a linear space. A set $S$ or elements $x, y, z, ...$ is a linear space if the following conditions are satisfied:
1. For any two elements $x, y \in S$ there is a uniquely defined a third element $z = x + y$, called their sum, such that:
	1. $x + y = y + x$
	2. $x + (y+z) = (x+y) + z$
	3. there exists an element $0$ having the property that $x + 0 = x$ $\forall x \in S$, and
	4. for every $x \in S$ there exists an element $-x$ such that $x + (-x) = 0$
2. For an arbitrary number $\alpha$ and element $x \in S$ there is defined an element $\alpha x$ such that:
	1. $\alpha(\beta x) = (\alpha \beta)x$
	2. $1\cdot x = x$
3. The operation of addition and multiplication are related in the following way:
	1. $(\alpha + \beta)x = \alpha x + \beta x$
	2. $\alpha(x + y) = \alpha x + \alpha y$

With the definition of linear space, we now define the normed space:
A linear space $S$ is said to be normed if to each element $x \in S$ there is made to correspond a nonnegative number $\lVert x \rVert$ which is called the norm of $x$ and such that:
1. $\lVert x \rVert$ iff $x = 0$
2. $\lVert \alpha x \rVert = \abs{\alpha} \lVert x \rVert$
3. $\lVert x + y \rVert \leq \lVert x \rVert + \lVert y \rVert$

It's easy to see that a normed space is also a metric space with the distance metric $d(x, y) = \lVert x - y \rVert$.

Equipped with linear space and normed space, we are ready to define a Banach space. But first, we need to define what it means for a space to be complete. Before that, we need to define Cauchy(fundamental) sequence and convergent sequence.

We call a sequence $\{x_n\}$ of points of a metric space $S$ a Cauchy(fundamental) sequence if it satisfies the Cauchy criterion: for an arbitrary $\epsilon > 0$ there exists an $N_{\epsilon}$ such that $d(x_{n'}, x_{n''}) < \epsilon$ $\forall n', n'' \geq N_{\epsilon}$.

We call a sequence $\{x_n\}$ of points of a metric space $S$ a convergent sequence if for an arbitrary $\epsilon > 0$ there exists a number $N_{\epsilon}$ such that $d(x_n, x) < \epsilon$ $\forall n \geq N_{epsilon}$. We say that $x_n$ converges to $x$. We write $\lim_{n\to \infty} x_n = x$.

Now we can define a complete sequence: A metric space $(S, d)$ is said to be complete if every Cauchy sequence in $S$ converges to some element in $S$. That is, every Cauchy sequence in $S$ is a convergent sequence that converges to an element in $S$.

With all those definitions, we can directly define what is a Banach space. A Banach space is a complete normed space. That is, a Banach space contains the limits of all it's Cauchy sequences.



